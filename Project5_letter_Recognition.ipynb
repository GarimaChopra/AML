{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project5_letter_Recognition.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNMTbj9OG9eCbN/FRY77rDp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GarimaChopra/AML/blob/main/Project5_letter_Recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ulUiXHMtI3-P"
      },
      "source": [
        "**The Letter Recognition dataset** contains 20,000 samples, where each sample is a vector of 16 geometric/statistical features about a letter. The goal of this assignment is to recognize letters using voting and ensemble classifiers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5xVAOL0HZPB"
      },
      "source": [
        "# Using Pandas for importing data from file \n",
        "import pandas as pd\n",
        "\n",
        "# Import matplotlib and seaborn libraries to visualize the data\n",
        "import matplotlib.pyplot as plt \n",
        "import seaborn as sns\n",
        "\n",
        "# Using numpy for to operate on multidimentional arrays.\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HAZnkK6jJhN6",
        "outputId": "e5557dc7-0353-45b2-9678-80a6b860d516"
      },
      "source": [
        "# Read raw file from github into a dataframe\n",
        "\n",
        "df= pd.read_csv('https://raw.githubusercontent.com/bforoura/AML/master/letters.csv')\n",
        "\n",
        "#verify if data is loaded\n",
        "df.shape"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20000, 17)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "dZLTw9J2KD2D",
        "outputId": "1cc4675f-14b5-4f09-b593-d1c638fd14cf"
      },
      "source": [
        "# view dataset\n",
        "df.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>x-box</th>\n",
              "      <th>y-box</th>\n",
              "      <th>width</th>\n",
              "      <th>high</th>\n",
              "      <th>onpix</th>\n",
              "      <th>x-bar</th>\n",
              "      <th>y-bar</th>\n",
              "      <th>x2bar</th>\n",
              "      <th>y2bar</th>\n",
              "      <th>xybar</th>\n",
              "      <th>x2ybr</th>\n",
              "      <th>xy2br</th>\n",
              "      <th>x-ege</th>\n",
              "      <th>xegvy</th>\n",
              "      <th>y-ege</th>\n",
              "      <th>yegvx</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>11</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>Z</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>9</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>8</td>\n",
              "      <td>7</td>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>7</td>\n",
              "      <td>10</td>\n",
              "      <td>P</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7</td>\n",
              "      <td>10</td>\n",
              "      <td>8</td>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>5</td>\n",
              "      <td>10</td>\n",
              "      <td>11</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>10</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>9</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>13</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>6</td>\n",
              "      <td>8</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>H</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6</td>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>10</td>\n",
              "      <td>7</td>\n",
              "      <td>9</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>H</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   x-box  y-box  width  high  onpix  ...  x-ege  xegvy  y-ege  yegvx  class\n",
              "0      2      4      4     3      2  ...      1      8      5      6      Z\n",
              "1      4      7      5     5      5  ...      2      9      7     10      P\n",
              "2      7     10      8     7      4  ...      2      5      5     10      S\n",
              "3      4      9      5     7      4  ...      3      8      0      8      H\n",
              "4      6      7      8     5      4  ...      3      8      3      7      H\n",
              "\n",
              "[5 rows x 17 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aE-c6YrxKt33",
        "outputId": "fd136779-1089-479d-af77-d1467c6eb0c3"
      },
      "source": [
        "#summarize the data set\n",
        "df.info()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 20000 entries, 0 to 19999\n",
            "Data columns (total 17 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   x-box   20000 non-null  int64 \n",
            " 1   y-box   20000 non-null  int64 \n",
            " 2   width   20000 non-null  int64 \n",
            " 3   high    20000 non-null  int64 \n",
            " 4   onpix   20000 non-null  int64 \n",
            " 5   x-bar   20000 non-null  int64 \n",
            " 6   y-bar   20000 non-null  int64 \n",
            " 7   x2bar   20000 non-null  int64 \n",
            " 8   y2bar   20000 non-null  int64 \n",
            " 9   xybar   20000 non-null  int64 \n",
            " 10  x2ybr   20000 non-null  int64 \n",
            " 11  xy2br   20000 non-null  int64 \n",
            " 12  x-ege   20000 non-null  int64 \n",
            " 13  xegvy   20000 non-null  int64 \n",
            " 14  y-ege   20000 non-null  int64 \n",
            " 15  yegvx   20000 non-null  int64 \n",
            " 16  class   20000 non-null  object\n",
            "dtypes: int64(16), object(1)\n",
            "memory usage: 2.6+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nnR1HZ0pKx12"
      },
      "source": [
        "**1) Problem Statement:** \n",
        "Prepare the training dataset for classification by performing transformations such as encoding, imputing, etc., as needed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wv5YrgETL-Is",
        "outputId": "1d422bae-214c-467e-db5a-4588cee54acf"
      },
      "source": [
        "# Check to see if there are any missing values\n",
        "df.isnull().sum()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "x-box    0\n",
              "y-box    0\n",
              "width    0\n",
              "high     0\n",
              "onpix    0\n",
              "x-bar    0\n",
              "y-bar    0\n",
              "x2bar    0\n",
              "y2bar    0\n",
              "xybar    0\n",
              "x2ybr    0\n",
              "xy2br    0\n",
              "x-ege    0\n",
              "xegvy    0\n",
              "y-ege    0\n",
              "yegvx    0\n",
              "class    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N0_JFQSuSVW8"
      },
      "source": [
        "As none of the columns contain null values  we dont need an imputer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8lAFO_mSx_u",
        "outputId": "8319b938-4890-457b-ab2b-2bd0502dde33"
      },
      "source": [
        "df.dtypes"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "x-box     int64\n",
              "y-box     int64\n",
              "width     int64\n",
              "high      int64\n",
              "onpix     int64\n",
              "x-bar     int64\n",
              "y-bar     int64\n",
              "x2bar     int64\n",
              "y2bar     int64\n",
              "xybar     int64\n",
              "x2ybr     int64\n",
              "xy2br     int64\n",
              "x-ege     int64\n",
              "xegvy     int64\n",
              "y-ege     int64\n",
              "yegvx     int64\n",
              "class    object\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMCvqvZsS4vC"
      },
      "source": [
        "All columns except the target 'class' column are numeric. We need to encode the target class\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ASW_KRKMazhY",
        "outputId": "df5160d6-890c-4cec-fffa-b54df518bd3b"
      },
      "source": [
        "# assigning values to X and Y\n",
        "\n",
        "X= df.drop(['class'], axis=1) #features\n",
        "Y = df['class'] #target\n",
        "\n",
        "# import encoder\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "# encode Y\n",
        "enc = LabelEncoder()\n",
        "enc.fit(Y)\n",
        "Y = pd.DataFrame(enc.transform(Y))\n",
        "\n",
        "Y=Y[0] #converting Y to 1D \n",
        "print(X.shape,Y.shape)\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(20000, 16) (20000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bsL8GLxNfdVf"
      },
      "source": [
        "**2) Problem Statement:** Plot label frequencies to verify that the letters A-Z are well-represented in the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "pKJ_eiXCfcI3",
        "outputId": "c64a450f-1d0d-408a-9746-8cfec3f31686"
      },
      "source": [
        "#Check whether the classes are balanced or not\n",
        "plt.subplots(figsize=(8,4))\n",
        "sns.barplot(x = df['class'].value_counts().sort_index(ascending=True).index , y = df['class'].value_counts().sort_index(ascending=True).values);\n",
        "plt.xlabel('Classes');\n",
        "plt.ylabel('Frequency');\n",
        "\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kcX-OAGHr0r4"
      },
      "source": [
        "All letters A-Z are well-represented in the dataset. U has maximum representation and Z has minimum representation. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Od3UyEwrsYBW"
      },
      "source": [
        "**3) Problem Statement**: Create a variety of classification models such as decision tree, random forest, extra trees, SVM, SGD, etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZadYrnEAsduP"
      },
      "source": [
        "# import statement for models\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# create decision trees \n",
        "dt_entropy = DecisionTreeClassifier(criterion='entropy', random_state=42)\n",
        "dt_gini = DecisionTreeClassifier(criterion='gini', random_state=42)\n",
        "\n",
        "# random forest and extra trees\n",
        "rfc = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "etc = ExtraTreesClassifier(random_state=42)\n",
        "\n",
        "# svc linear, poly, rbf\n",
        "svc_linear = SVC(kernel='linear', random_state=42, probability=True)\n",
        "svc_poly = SVC(kernel='poly', random_state=42, probability=True)\n",
        "svc_rbf = SVC(kernel='rbf', random_state=42, probability=True)\n",
        "\n",
        "#sgd\n",
        "sgd = SGDClassifier(loss = 'log', random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gG0EIqthxw3x"
      },
      "source": [
        "**4) Problem Statement:** Train each model separately and cross-validate using cross_validate_model():\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3_mP-jvvdgO"
      },
      "source": [
        "# import k fold, cross_val_score\n",
        "from sklearn.model_selection import KFold, cross_val_score\n",
        "\n",
        "# method to train and cross validate\n",
        "\n",
        "def cross_validate_model (classifier_model, X, y):\n",
        "           kfold = KFold(n_splits=3, shuffle=True, random_state=10)\n",
        "          # perform model cross validation on the shuffled folds\n",
        "           results = cross_val_score(classifier_model, X, y, cv=kfold)\n",
        "           # return the mean score for all folds\n",
        "           return results.mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDUwWgHi0MAz"
      },
      "source": [
        "# cross validate the decision tree model\n",
        "dt_entropy_score = cross_validate_model(dt_entropy , X, Y)\n",
        "dt_gini_score = cross_validate_model(dt_gini , X, Y)\n",
        "\n",
        "# cross validate the random forest and extra trees\n",
        "rfc_score = cross_validate_model(rfc , X, Y)\n",
        "etc_score = cross_validate_model(etc , X, Y)\n",
        "\n",
        "# cross validate  svc linear, poly, rbf\n",
        "svc_linear_score = cross_validate_model(svc_linear , X, Y)\n",
        "svc_poly_score = cross_validate_model(svc_poly , X, Y)\n",
        "svc_rbf_score = cross_validate_model(svc_rbf , X, Y)\n",
        "\n",
        "\n",
        "# cross validate the SGD\n",
        "sgd_score = cross_validate_model(sgd , X, Y)\n",
        "\n",
        "print(\"Decision Tree Entropy Score:\", dt_entropy_score)\n",
        "print(\"Decision Tree Gini Score:\", dt_gini_score)\n",
        "print(\"Random Forest Classifier Score:\", rfc_score)\n",
        "print(\"Extra Tree Classifier Score:\", etc_score)\n",
        "print(\"SVC Linear Score:\", svc_linear_score )\n",
        "print(\"SVC Poly Score\", svc_poly_score)\n",
        "print(\"SVC RBF Score:\", svc_rbf_score)\n",
        "print(\"SGD Score:\", sgd_score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNIijOGC-R4h"
      },
      "source": [
        "**5) Problem Statement:** Train the voting classifier model and cross-validate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tei_Cayl-RHT"
      },
      "source": [
        " # voting ensemble made by above models\n",
        "\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        " # hard voting classifier\n",
        "hard_voting_clf = VotingClassifier(\n",
        "    estimators=[('dt_entropy', dt_entropy), ('dt_gini', dt_gini), ('rfc', rfc), ('etc', etc), ('svc_linear', svc_linear), \n",
        "                ('svc_poly',svc_poly), ('svc_rbf', svc_rbf), ('sgd', sgd)],\n",
        "    voting='hard')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4PUe0RgDfXd"
      },
      "source": [
        "hard_voting_score = cross_validate_model(hard_voting_clf, X, Y)\n",
        "print(\"Voting Ensemble Score:\", hard_voting_score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "St7Mh4IrG6Hi"
      },
      "source": [
        "**6) Problem Statement:**  Plot the obtained accuracy scores in a bar chart. Has the voting classifier outperformed each individual model? Explain why or why not."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4QCBqhlHCUL"
      },
      "source": [
        "# Plotting all models\n",
        "\n",
        "labels = ['DT(Entropy)', 'DT(Gini)', 'RFC', 'ETC', 'SVC(lin)', 'SVC(Poly)', 'SVC(RBF)', 'SGD', 'Voting(hard)']\n",
        "training_scores = [dt_entropy_score, dt_gini_score, rfc_score, etc_score, svc_linear_score , svc_poly_score, svc_rbf_score, sgd_score, hard_voting_score]\n",
        "\n",
        "\n",
        "x = np.arange(len(labels))  # the label locations\n",
        "width = 0.35  # the width of the bars\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(15,7))\n",
        "rects1 = ax.bar(x - width/2, training_scores, width, color='orange')\n",
        "\n",
        "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
        "ax.set_ylabel('Accuracy')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(labels)\n",
        "\n",
        "\n",
        "plt.title('Model Comparisons')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHpLMELhG3ZA"
      },
      "source": [
        "\n",
        "Voting Classifier performs better than most models but has not outperformed all models. Extra Tree Classifier(ETC) and Random Forest Classifier(RFC) perform better than Voting. \n",
        "The reason for this is that Voting Classifier predicts the class with highest probability estimate . Every individual classifier votes for a class, and the majority wins. This means some comprising models are not well calibrated"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A9Mk6e1ZLhr9"
      },
      "source": [
        "**7) Problem Statement:** Plot feature_importances discovered by the random forest model to get a plot . What do these values mean, and do all tree models agree on the importance of features?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5MNgiCkwLx2G"
      },
      "source": [
        "import matplotlib.pyplot as pyplot\n",
        "\n",
        "# feature importances from the random forest model\n",
        "rfc.fit(X,Y)\n",
        "importance = rfc.feature_importances_\n",
        "\n",
        "pyplot.figure(figsize=[10, 8])\n",
        "# plot feature importances\n",
        "pyplot.bar(X.columns, importance)\n",
        "\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OtTZxATCQTP4"
      },
      "source": [
        "# summarize feature importances in descending order\n",
        "feature_importances = pd.DataFrame(importance,\n",
        "                                 index = X.columns,\n",
        "                             columns=['importance']).sort_values('importance',  ascending=False)\n",
        "\n",
        "print(feature_importances)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MlGoqqr6Nx4u"
      },
      "source": [
        "The above plot show the features that random forest found most significant. These features were most useful in classifying objects to a particular class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDXxfzT5myQM"
      },
      "source": [
        "# feature importances from the extra tree model\n",
        "etc.fit(X, Y);\n",
        "etc_importance = etc.feature_importances_\n",
        "\n",
        "feature_importances_etc = pd.DataFrame(etc_importance,\n",
        "                                 index = X.columns,\n",
        "                             columns=['etc_importance']).sort_values('etc_importance',  ascending=False)\n",
        "\n",
        "print(feature_importances_etc )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eI40VbfqpmfZ"
      },
      "source": [
        "# get feature importances from the dt (entropy) model\n",
        "dt_entropy.fit(X, Y);\n",
        "dt_entropy_importance =dt_entropy.feature_importances_\n",
        "\n",
        "feature_importances_dt_entropy = pd.DataFrame(dt_entropy_importance,\n",
        "                                 index = X.columns,\n",
        "                             columns=['dt_entropy_importance']).sort_values('dt_entropy_importance',  ascending=False)\n",
        "print(feature_importances_dt_entropy )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VeHuoPE5pol0"
      },
      "source": [
        "# get feature importances from the dt (gini) model\n",
        "dt_gini.fit(X, Y);\n",
        "dt_gini_importance = dt_gini.feature_importances_\n",
        "\n",
        "feature_importances_dt_gini_importance  = pd.DataFrame(dt_gini_importance ,\n",
        "                                 index = X.columns,\n",
        "                             columns=['dt_gini_importance ']).sort_values('dt_gini_importance ',  ascending=False)\n",
        "print(feature_importances_dt_gini_importance )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCib8tegqid0"
      },
      "source": [
        "pyplot.figure(figsize=[20, 10])\n",
        "\n",
        "# 1\n",
        "pyplot.subplot(221).set_title(\"Random Forest Feature Importance\")\n",
        "pyplot.bar(X.columns, importance)\n",
        "\n",
        "# 2\n",
        "pyplot.subplot(222).set_title(\"Extra Trees Feature Importance\")\n",
        "pyplot.bar(X.columns, etc_importance, color=\"yellow\")\n",
        "\n",
        "# 3\n",
        "pyplot.subplot(223).set_title(\"Entropy Decision Tree Importance\")\n",
        "pyplot.bar(X.columns, dt_entropy_importance, color=\"purple\")\n",
        "\n",
        "# 4\n",
        "pyplot.subplot(224).set_title(\"Gini Decision Tree Importance\")\n",
        "pyplot.bar(X.columns, dt_gini_importance, color=\"green\")\n",
        "\n",
        "\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cgXEjlVZqGUG"
      },
      "source": [
        "X-ege and Y-ege are the most important features for all models , but the rest of the feature preference differs between models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hyL8T_4YSWkg"
      },
      "source": [
        "**8) Problem Statement :** Train K-Means on the dataset, and plot the Elbow and Silhouette inertia values . Explain the results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-djbH9RDSV5h"
      },
      "source": [
        "# scaling data as K-means works better on scaled data\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X)\n",
        "K_mean_X =  pd.DataFrame(scaler.transform(X), columns=X.columns);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RA89WCB2TgfV"
      },
      "source": [
        "from sklearn.cluster import KMeans\n",
        "\n",
        "kmeans_per_k = [KMeans(n_clusters=k, random_state=42).fit(K_mean_X)\n",
        "                for k in range(1, 10)] \n",
        "inertias = [model.inertia_ for model in kmeans_per_k]\n",
        "print(inertias)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BFLG9e7dXPGQ"
      },
      "source": [
        "Inertia decreases as K increases as distance from centroid decreases"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8lX0BVf9UwGE"
      },
      "source": [
        "# plotting Elbow plot\n",
        "\n",
        "plt.figure(figsize=(8, 3.5))\n",
        "plt.plot(range(1, 10), inertias, \"bo-\")\n",
        "plt.xlabel(\"$k$\", fontsize=14)\n",
        "plt.ylabel(\"Inertia\", fontsize=14)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PIEufqEecSvZ"
      },
      "source": [
        "The elbow plot indicates that the number of clusters should be 2 (k = 2). \n",
        "To determine the optimal number of clusters, we have to select the value of k at the “elbow” ie the point after which the distortion/inertia start decreasing in a linear fashion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6gupDIGcSOW"
      },
      "source": [
        "from sklearn.metrics import silhouette_score\n",
        "silhouette_scores = [silhouette_score(K_mean_X, model.labels_)\n",
        "                     for model in kmeans_per_k[1:]]\n",
        "print(silhouette_scores)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7NdV4sM0dkBy"
      },
      "source": [
        "\n",
        "plt.figure(figsize=(8, 3))\n",
        "plt.plot(range(2, 10), silhouette_scores, \"bo-\")\n",
        "plt.xlabel(\"$k$\", fontsize=14)\n",
        "plt.ylabel(\"Silhouette score\", fontsize=14)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g4akLD-cfwp-"
      },
      "source": [
        "Silhouette score at K=2 seems to be dense and nicely separated (it is closest to 1). The score of near to 0 at k=4 means that clusters are overlapping, data belonging to clusters may be wrong/incorrect."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDYvQA6hgyci"
      },
      "source": [
        "**9) Problem Statement:** Create a 3D plot of the target concept against the two most influential features from Step 7. How does the visualized data match the results obtained in Step 7"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQIxzHU_hYXJ"
      },
      "source": [
        "fig = plt.figure(figsize=(10,10))\n",
        "ax = plt.axes(projection='3d')\n",
        "\n",
        "# Set up data for three-dimensional scattered points; use the 26 labels for color map\n",
        "ax.scatter3D(xs=X[\"x-ege\"], ys=X[\"y-ege\"], zs=Y, c=Y)\n",
        "\n",
        "# rotate the axes and update the view\n",
        "ax.view_init(30, 45)\n",
        "plt.draw()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbIE5tOqs-B0"
      },
      "source": [
        "The two features x-ege and y-ege are able to divide the target in distinct differentiable clusters as clearly shown in the 3D plot\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kfzEMP7jiUW2"
      },
      "source": [
        "**Summary**\n",
        "In this exercise, the Letter recognition dataset was used. Below are the findings of the study:\n",
        "\n",
        "1.   It was found that data contains no null values, hence very little pre processing was required on the dataset\n",
        "2.   Data set is well represented for all target values\n",
        "3.   Extra Tree Classifier(96.8%) and Random Forest Classifier (95.8%)have the best cross validation score followed by Voting Classifier (95.6%)\n",
        "4.   x-ege is the most important feature for random tree classifier and other classifier models followed by y-ege. Rest of the feature importance differs accross models\n",
        "5. The elbow and sihlouette plots indicate the optimal number of clusters for K-means is 2\n",
        "6. The two features x-ege and y-ege are able to divide the target in distinct differentiable clusters as clearly shown in the 3D plot\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}